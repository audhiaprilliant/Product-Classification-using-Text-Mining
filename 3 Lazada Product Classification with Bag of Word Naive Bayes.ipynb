{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazada Product Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audhi Aprilliant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:29:13.169770Z",
     "start_time": "2020-03-18T04:29:12.545426Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd                   # Dataframe manipulation\n",
    "import numpy as np                    # Mathematics operation\n",
    "from sklearn.feature_extraction.text import CountVectorizer   # Bag of word\n",
    "from sklearn.model_selection import StratifiedKFold,learning_curve,cross_val_score\n",
    "from sklearn.model_selection import train_test_split          # Splitting data\n",
    "from sklearn.naive_bayes import MultinomialNB                 # Modelling with Multinomial Naive Bayes\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:29:17.334662Z",
     "start_time": "2020-03-18T04:29:13.272157Z"
    }
   },
   "outputs": [],
   "source": [
    "data_lazada_clean = pd.read_csv('Datasets/interim/1 Lazada-product after Preprocessing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T05:12:20.546575Z",
     "start_time": "2020-03-18T05:12:20.520580Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of Lazada data:\n",
      "6735 rows and 2 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lazada exclusive infinix smart gb dual camera ...</td>\n",
       "      <td>handphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lazada special edition infinix hot gb triple c...</td>\n",
       "      <td>handphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>realme c hp murah mah battery octa core hio p ...</td>\n",
       "      <td>handphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vivo y hp gb gb gb all screen inch mp hio p tr...</td>\n",
       "      <td>handphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realme i hp gb gb gb gb qualcomm snapdragon ai...</td>\n",
       "      <td>handphone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   category\n",
       "0  lazada exclusive infinix smart gb dual camera ...  handphone\n",
       "1  lazada special edition infinix hot gb triple c...  handphone\n",
       "2  realme c hp murah mah battery octa core hio p ...  handphone\n",
       "3  vivo y hp gb gb gb all screen inch mp hio p tr...  handphone\n",
       "4  realme i hp gb gb gb gb qualcomm snapdragon ai...  handphone"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Dimension of Lazada data:\\n{}'.format(data_lazada_clean.shape[0]),\n",
    "      'rows and {}'.format(data_lazada_clean.shape[1]),'columns')\n",
    "data_lazada_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:29:19.194907Z",
     "start_time": "2020-03-18T04:29:18.412905Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "makeup       2713\n",
      "pakaian      2380\n",
      "handphone    1642\n",
      "Name: category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_lazada_clean['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:29:20.179100Z",
     "start_time": "2020-03-18T04:29:19.201436Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Category MakeUp ---\n",
      "mascara       1429\n",
      "waterproof     603\n",
      "maskara        464\n",
      "matte          321\n",
      "make           313\n",
      "dtype: int64\n",
      "--- Category Pakaian ---\n",
      "tunik     2973\n",
      "wanita    1422\n",
      "baju       756\n",
      "atas       652\n",
      "murah      543\n",
      "dtype: int64\n",
      "--- Category Handphone ---\n",
      "gb         1790\n",
      "garansi     758\n",
      "resmi       723\n",
      "ram         504\n",
      "hp          335\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Subsetting\n",
    "data_makeup = data_lazada_clean.loc[data_lazada_clean['category'] == 'makeup',:]\n",
    "data_pakaian = data_lazada_clean.loc[data_lazada_clean['category'] == 'pakaian',:]\n",
    "data_handphone = data_lazada_clean.loc[data_lazada_clean['category'] == 'handphone',:]\n",
    "# Counting term frequency each categories\n",
    "term_freq_makeup = pd.Series(' '.join(data_makeup['title']).split(' ')).value_counts()\n",
    "term_freq_pakaian = pd.Series(' '.join(data_pakaian['title']).split(' ')).value_counts()\n",
    "term_freq_handphone = pd.Series(' '.join(data_handphone['title']).split(' ')).value_counts()\n",
    "# Print\n",
    "print('--- Category MakeUp ---\\n',term_freq_makeup[:5],sep='')\n",
    "print('--- Category Pakaian ---\\n',term_freq_pakaian[:5],sep='')\n",
    "print('--- Category Handphone ---\\n',term_freq_handphone[:5],sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Splitting the Data into Training, Testing, and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:29:20.794596Z",
     "start_time": "2020-03-18T04:29:20.205018Z"
    }
   },
   "outputs": [],
   "source": [
    "train,validation = train_test_split(data_lazada_clean,test_size=0.2,random_state=123)\n",
    "test = validation.loc[:,['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:29:20.833405Z",
     "start_time": "2020-03-18T04:29:20.818545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dims of training data   : 5388 rows and 2 variables\n",
      "Dims of testing data    : 1347 rows and 1 variables\n",
      "Dims of validation data : 1347 rows and 2 variables\n"
     ]
    }
   ],
   "source": [
    "print('Dims of training data   : {}'.format(train.shape[0])+' rows and {}'.format(train.shape[1])+' variables')\n",
    "print('Dims of testing data    : {}'.format(test.shape[0])+' rows and {}'.format(test.shape[1])+' variables')\n",
    "print('Dims of validation data : {}'.format(validation.shape[0])+\n",
    "      ' rows and {}'.format(validation.shape[1])+' variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Creating Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:51:48.246431Z",
     "start_time": "2020-03-18T04:51:48.072947Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train = train['category'].reset_index(drop=True)\n",
    "X_train = train['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:43:22.220547Z",
     "start_time": "2020-03-18T04:43:21.284270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "CPU times: user 224 ms, sys: 14.5 ms, total: 239 ms\n",
      "Wall time: 782 ms\n"
     ]
    }
   ],
   "source": [
    "# Bag of word\n",
    "print('Creating the bag of words...')\n",
    "vectorizer = CountVectorizer(analyzer = 'word',\n",
    "                             tokenizer = None, \n",
    "                             preprocessor = None,\n",
    "                             stop_words = None, \n",
    "                             max_features = 5000) \n",
    "%time train_data_features = vectorizer.fit_transform(X_train)\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:48:31.452562Z",
     "start_time": "2020-03-18T04:48:31.394880Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aajsbolc</th>\n",
       "      <th>ab</th>\n",
       "      <th>abad</th>\n",
       "      <th>abang</th>\n",
       "      <th>abel</th>\n",
       "      <th>abelia</th>\n",
       "      <th>abg</th>\n",
       "      <th>abi</th>\n",
       "      <th>abis</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouhmhgt</th>\n",
       "      <th>zoya</th>\n",
       "      <th>zpro</th>\n",
       "      <th>zs</th>\n",
       "      <th>zskl</th>\n",
       "      <th>zte</th>\n",
       "      <th>zyjdjclu</th>\n",
       "      <th>zyrex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aajsbolc  ab  abad  abang  abel  abelia  abg  abi  abis  ...  zone  \\\n",
       "0   0         0   0     0      0     0       0    0    0     0  ...     0   \n",
       "1   0         0   0     0      0     0       0    0    0     0  ...     0   \n",
       "2   0         0   0     0      0     0       0    0    0     0  ...     0   \n",
       "3   0         0   0     0      0     0       0    0    0     0  ...     0   \n",
       "4   0         0   0     0      0     0       0    0    0     0  ...     0   \n",
       "\n",
       "   zoom  zouhmhgt  zoya  zpro  zs  zskl  zte  zyjdjclu  zyrex  \n",
       "0     0         0     0     0   0     0    0         0      0  \n",
       "1     0         0     0     0   0     0    0         0      0  \n",
       "2     0         0     0     0   0     0    0         0      0  \n",
       "3     0         0     0     0   0     0    0         0      0  \n",
       "4     0         0     0     0   0     0    0         0      0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_data_features,columns=vectorizer.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Data Modelling using 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:52:19.210022Z",
     "start_time": "2020-03-18T04:51:51.153203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in CV - 1: 0.9944341372912802\n",
      "Accuracy in CV - 2: 0.9962894248608535\n",
      "Accuracy in CV - 3: 0.9962894248608535\n",
      "Accuracy in CV - 4: 0.9925788497217068\n",
      "Accuracy in CV - 5: 1.0\n",
      "Accuracy in CV - 6: 0.9981447124304267\n",
      "Accuracy in CV - 7: 0.9925788497217068\n",
      "Accuracy in CV - 8: 1.0\n",
      "Accuracy in CV - 9: 0.9944237918215614\n",
      "Accuracy in CV - 10: 0.9944237918215614\n",
      "Average of accuracy: 0.995916298252995\n"
     ]
    }
   ],
   "source": [
    "# Stratified 10-CV\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "accuracy = []\n",
    "i = 0\n",
    "model = MultinomialNB()\n",
    "for train_index,test_index in skf.split(train_data_features,Y_train):\n",
    "    i+=1\n",
    "    X_train_split,X_test_split = train_data_features[train_index],train_data_features[test_index]\n",
    "    y_train_split,y_test_split = Y_train[train_index],Y_train[test_index]\n",
    "    model.fit(X_train_split,y_train_split.values)\n",
    "    y_pred = model.predict(X_test_split)\n",
    "    val =  accuracy_score(y_test_split,y_pred)\n",
    "    accuracy.append(val)\n",
    "    print(f'Accuracy in CV - {i}: {val}')\n",
    "print('Average of accuracy: {}'.format(sum(accuracy)/len(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:53:59.749208Z",
     "start_time": "2020-03-18T04:53:58.545075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.19 s, sys: 0 ns, total: 1.19 s\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "# Data modelling with Naive Bayes\n",
    "%time nb = model.fit(train_data_features,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Model Evaluation with Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:53:16.087663Z",
     "start_time": "2020-03-18T04:53:15.523231Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_val = validation['category'].reset_index(drop=True)\n",
    "X_val = validation['title']\n",
    "val_data_features = vectorizer.transform(X_val)\n",
    "val_data_features = val_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:54:02.951209Z",
     "start_time": "2020-03-18T04:54:02.854924Z"
    }
   },
   "outputs": [],
   "source": [
    "val_pred = nb.predict(val_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T05:06:35.957777Z",
     "start_time": "2020-03-18T05:06:35.660353Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Predicted Handphone  Predicted MakeUp  Predicted Pakaian\n",
      "Actual Handphone                  341                 1                  0\n",
      "Actual MakeUp                       1               535                  0\n",
      "Actual Pakaian                      0                 0                469\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   handphone      0.997     0.997     0.997       342\n",
      "      makeup      0.998     0.998     0.998       536\n",
      "     pakaian      1.000     1.000     1.000       469\n",
      "\n",
      "    accuracy                          0.999      1347\n",
      "   macro avg      0.998     0.998     0.998      1347\n",
      "weighted avg      0.999     0.999     0.999      1347\n",
      "\n",
      "Accuracy Score : 0.9985152190051967\n",
      "F1 Score       : 0.9985152190051967\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(Y_val,val_pred)\n",
    "f1score = f1_score(Y_val,val_pred,average='weighted')\n",
    "cm = pd.DataFrame(confusion_matrix(Y_val,val_pred),\n",
    "                  columns = ['Predicted Handphone','Predicted MakeUp','Predicted Pakaian'],\n",
    "                  index = ['Actual Handphone','Actual MakeUp','Actual Pakaian'])\n",
    "print(cm)\n",
    "print('\\n',classification_report(Y_val,val_pred,digits=3))\n",
    "print('Accuracy Score : ' + str(acc))\n",
    "print('F1 Score       : ' + str(f1score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
